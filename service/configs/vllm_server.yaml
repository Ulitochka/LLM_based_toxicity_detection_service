
model_config:
  quant8: False
  quant4: False
  token: ${HF_TOKEN}
  peft: False
  fuse_layers: False
  use_flash_attn: False
  model_name: 2025_07_02-04_48_077cd82859_google_gemma-2-2b-it_awq

data_config:
  task_type: cls_toxic
  prefix: 'токсичный текст: '
  collator_type: simple
  max_target_len: 5
  max_input_len: 1024

server_config:
  max_num_seqs: '64'
  task: 'generate'
  kv_cache_dtype: 'fp8'
  quantization: 'awq'
